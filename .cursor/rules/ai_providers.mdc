---
description: Guidelines for managing Task Master AI providers and models.
globs: 
alwaysApply: false
---

# Task Master AI Provider Management

This rule guides AI assistants on how to view, configure, and interact with the different AI providers and models supported by Task Master. For internal implementation details of the service layer, see [`ai_services.mdc`](mdc:.cursor/rules/ai_services.mdc).

-   **Primary Interaction:**
    -   Use the `models` MCP tool or the `task-master models` CLI command to manage AI configurations. See [`taskmaster.mdc`](mdc:.cursor/rules/taskmaster.mdc) for detailed command/tool usage.

-   **Configuration Roles:**
    -   Task Master uses three roles for AI models:
        -   `main`: Primary model for general tasks (generation, updates).
        -   `research`: Model used when the `--research` flag or `research: true` parameter is used (typically models with web access or specialized knowledge).
        -   `fallback`: Model used if the primary (`main`) model fails.
    -   Each role is configured with a specific `provider:modelId` pair (e.g., `openai:gpt-4o`).

-   **Viewing Configuration & Available Models:**
    -   To see the current model assignments for each role and list all models available for assignment:
        -   **MCP Tool:** `models` (call with no arguments or `listAvailableModels: true`)
        -   **CLI Command:** `task-master models`
    -   The output will show currently assigned models and a list of others, prefixed with their provider (e.g., `google:gemini-2.5-pro-exp-03-25`).

-   **Setting Models for Roles:**
    -   To assign a model to a role:
        -   **MCP Tool:** `models` with `setMain`, `setResearch`, or `setFallback` parameters.
        -   **CLI Command:** `task-master models` with `--set-main`, `--set-research`, or `--set-fallback` flags.
    -   **Crucially:** When providing the model ID to *set*, **DO NOT include the `provider:` prefix**. Use only the model ID itself.
        -   ✅ **DO:** `models(setMain='gpt-4o')` or `task-master models --set-main=gpt-4o`
        -   ❌ **DON'T:** `models(setMain='openai:gpt-4o')` or `task-master models --set-main=openai:gpt-4o`
    -   The tool/command will automatically determine the provider based on the model ID.

-   **Supported Providers & Required API Keys:**
    -   Task Master integrates with various providers via the Vercel AI SDK.
    -   **API keys are essential** for most providers and must be configured correctly.
    -   **Key Locations** (See [`dev_workflow.mdc`](mdc:.cursor/rules/dev_workflow.mdc) - Configuration Management):
        -   **MCP/Cursor:** Set keys in the `env` section of `.cursor/mcp.json`.
        -   **CLI:** Set keys in a `.env` file in the project root.
    -   **Provider List & Keys:**
        -   **`anthropic`**: Requires `ANTHROPIC_API_KEY`.
        -   **`google`**: Requires `GOOGLE_API_KEY`.
        -   **`openai`**: Requires `OPENAI_API_KEY`.
        -   **`perplexity`**: Requires `PERPLEXITY_API_KEY`.
        -   **`xai`**: Requires `XAI_API_KEY`.
        -   **`mistral`**: Requires `MISTRAL_API_KEY`.
        -   **`azure`**: Requires `AZURE_OPENAI_API_KEY` and `AZURE_OPENAI_ENDPOINT`.
        -   **`openrouter`**: Requires `OPENROUTER_API_KEY`.
        -   **`ollama`**: Typically requires `OLLAMA_API_KEY` *and* `OLLAMA_BASE_URL` (default: `http://localhost:11434/api`). *Check specific setup.*

-   **Troubleshooting:**
    -   If AI commands fail (especially in MCP context):
        1.  **Verify API Key:** Ensure the correct API key for the *selected provider* (check `models` output) exists in the appropriate location (`.cursor/mcp.json` env or `.env`).
        2.  **Check Model ID:** Ensure the model ID set for the role is valid (use `models` listAvailableModels/`task-master models`).
        3.  **Provider Status:** Check the status of the external AI provider's service.
        4.  **Restart MCP:** If changes were made to configuration or provider code, restart the MCP server.